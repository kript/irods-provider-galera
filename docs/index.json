[
{
	"uri": "https://mjstealey.github.io/irods-provider-galera/galera-vms/",
	"title": "Galera VMs",
	"tags": [],
	"description": "Galera VMs used for testing",
	"content": "Three CentOS Linux release 7.3.1611 (Core) virtual machines (VMs) were stood up to establish an iRODS provider Galera cluster testbed. Each VM is configured with a user account named galera which has rights to run Docker and not much else. galera1.env WSREP_ON=ON WSREP_PROVIDER=/usr/lib64/galera/libgalera_smm.so WSREP_PROVIDER_OPTIONS=&#39;evs.keepalive_period=PT3S; evs.suspect_timeout=PT30S; evs.inactive_timeout=PT1M; evs.install_timeout=PT1M; evs.join_retrans_period=PT1.5S&#39; WSREP_CLUSTER_ADDRESS=&#39;gcomm://172.25.8.171,172.25.8.172,172.25.8.173&#39; WSREP_CLUSTER_NAME=&#39;galera&#39; WSREP_NODE_ADDRESS=&#39;172.25.8.171&#39; WSREP_NODE_NAME=&#39;galera-1&#39; WSREP_SST_METHOD=rsync BINLOG_FORMAT=row DEFAULT_STORAGE_ENGINE=InnoDB INNODB_AUTOINC_LOCK_MODE=2 BIND_ADDRESS=0.0.0.0 IRODS_SERVICE_ACCOUNT_NAME=irods IRODS_SERVICE_ACCOUNT_GROUP=irods IRODS_SERVER_ROLE=1 ODBC_DRIVER_FOR_MYSQL=2 IRODS_DATABASE_SERVER_HOSTNAME=localhost IRODS_DATABASE_SERVER_PORT=3306 IRODS_DATABASE_NAME=ICAT IRODS_DATABASE_USER_NAME=irods IRODS_DATABASE_PASSWORD=temppassword IRODS_DATABASE_USER_PASSWORD_SALT=tempsalt IRODS_ZONE_NAME=tempZone IRODS_PORT=1247 IRODS_PORT_RANGE_BEGIN=20000 IRODS_PORT_RANGE_END=20199 IRODS_CONTROL_PLANE_PORT=1248 IRODS_SCHEMA_VALIDATION=file:///var/lib/irods/configuration_schemas IRODS_SERVER_ADMINISTRATOR_USER_NAME=rods IRODS_SERVER_ZONE_KEY=TEMPORARY_zone_key IRODS_SERVER_NEGOTIATION_KEY=TEMPORARY_32byte_negotiation_key IRODS_CONTROL_PLANE_KEY=TEMPORARY__32byte_ctrl_plane_key IRODS_SERVER_ADMINISTRATOR_PASSWORD=rods IRODS_VAULT_DIRECTORY=/Vault MYSQL_ROOT_PASSWORD=rods init-galera $ ./init-galera &amp;amp;&amp;amp; docker attach --sig-proxy=false irods-galera-1 #!/usr/bin/env bash docker stop irods-galera-1 docker rm -fv irods-galera-1 sleep 2s docker run -d --name irods-galera-1 -h galera-1.edc.renci.org \ -v /var/galera/vault:/Vault \ -v /var/galera/var_mysql:/var/lib/mysql \ -v /var/galera/var_irods:/var/lib/irods \ -v /var/galera/etc_irods:/etc/irods \ -v /home/galera/init:/init \ --env-file=/home/galera/galera1.env \ -p 3306:3306 \ -p 4444:4444 \ -p 4567:4567 \ -p 4568:4568 \ -p 1247:1247 \ -p 1248:1248 \ -p 20000-20199:20000-20199 \ mjstealey/irods-provider-galera:4.2.0 -ivd setup_irods.py exit 0; mkresc $ ./mkresc galera1Resc #!/usr/bin/env bash RESC=$1 docker exec -u irods irods-galera-1 iadmin mkresc $RESC unixfilesystem galera-1.edc.renci.org:/Vault docker exec -u irods irods-galera-1 iadmin lr exit 0; "
},
{
	"uri": "https://mjstealey.github.io/irods-provider-galera/three-node-test/",
	"title": "Three node test script",
	"tags": [],
	"description": "Three node test script in Docker",
	"content": "Three node test in Docker network A three node test script was created that demonstrates the basic principles of using the MariaDB Galera cluster as the iRODS catalog for multiple provider nodes. The script does the following. Creates a local docker network named galeranet so that known IP addresses can be assigned to each node Stands up the initial bootstrap node using mostly defaults as set by the Docker image. Stands up two additional nodes in series that join the cluster named galera as they discover others on the local galeranet network. As each node completes it&amp;rsquo;s stand up routine, it will report back the number of nodes participating as the wsrep_cluster_size, show the named databases including ICAT, grants for user &amp;lsquo;irods&amp;rsquo;@&amp;lsquo;localhost&amp;rsquo;, and finally print out all tables within the ICAT database. Since this initial test was performed on a single VM using a docker network, it was not subjected to any rigorous external testing and only subject to simple iCommands to validate synchronization between nodes and partitioning between named node resource definitions. A dedicated set of Galera VMs were established for the purpose of vetting the performance of the three node configuration in a more real world setting. three-node-test.sh #!/usr/bin/env bash REPO_DIR=$(pwd) # create docker network if it does not exist GALERANET=$(docker network inspect galeranet) echo &amp;quot;### create docker network galeranet if it does not exist ###&amp;quot; if [[ &amp;quot;${GALERANET}&amp;quot; = &#39;[]&#39; ]]; then docker network create --subnet=172.18.0.0/16 galeranet fi # stop / remove existing containers echo &amp;quot;### stop / remove existing containers ###&amp;quot; if [[ -n $(docker ps -a | grep galera-node) ]]; then docker stop irods-galera-node-1 irods-galera-node-2 irods-galera-node-3 docker rm -fv irods-galera-node-1 irods-galera-node-2 irods-galera-node-3 fi # show usage echo &amp;quot;### show usage ###&amp;quot; docker run --rm mjstealey/irods-provider-galera:4.2.0 -h setup_irods.py # init irods-galera-node-1 echo &amp;quot;### start irods-galera-node-1 and initialize cluster &#39;galera&#39; with initialize.sql file ###&amp;quot; docker run -d --name irods-galera-node-1 -h irods-galera-node-1 \ --env-file=env/irods-galera-node-1.env \ --net galeranet \ --ip 172.18.0.2 \ --add-host irods-galera-node-2:172.18.0.3 \ --add-host irods-galera-node-3:172.18.0.4 \ mjstealey/irods-provider-galera:4.2.0 -vi setup_irods.py exec 3&amp;gt;&amp;amp;2 exec 2&amp;gt; /dev/null CL_SIZE=0 echo -n &amp;quot;Waiting for irods-galera-node-1 &amp;quot; while [ &amp;quot;${CL_SIZE}&amp;quot; != &#39;1&#39; ]; do sleep 2s LINE=$(docker exec irods-galera-node-1 mysql -uroot -ptemppassword -e &amp;quot;SHOW STATUS LIKE &#39;wsrep_cluster_size&#39;;&amp;quot; | grep wsrep_cluster_size) CL_SIZE=$(echo ${LINE} | cut -d &#39; &#39; -f 2) echo -n &amp;quot;.&amp;quot; done echo &amp;quot;&amp;quot; exec 2&amp;gt;&amp;amp;3 echo &amp;quot;[node-1 MySQL]&amp;gt; SHOW STATUS LIKE &#39;wsrep_cluster_size&#39;;&amp;quot; docker exec -ti irods-galera-node-1 mysql -uroot -ptemppassword -e &amp;quot;SHOW STATUS LIKE &#39;wsrep_cluster_size&#39;;&amp;quot; echo &amp;quot;[node-1 MySQL]&amp;gt; SHOW databases;&amp;quot; docker exec -ti irods-galera-node-1 mysql -uroot -ptemppassword -e &amp;quot;SHOW databases;&amp;quot; echo &amp;quot;[node-1 MySQL]&amp;gt; SHOW grants FOR &#39;irods&#39;@&#39;localhost&#39;;&amp;quot; docker exec -ti irods-galera-node-1 mysql -uroot -ptemppassword ICAT -e \ &amp;quot;SHOW grants FOR &#39;irods&#39;@&#39;localhost&#39;;&amp;quot; # init irods-galera-node-2 echo &amp;quot;### start irods-galera-node-2 and join cluster &#39;irods-galera&#39; ###&amp;quot; docker run -d --name irods-galera-node-2 -h irods-galera-node-2 \ --env-file=env/irods-galera-node-2.env \ --net galeranet \ --ip 172.18.0.3 \ --add-host irods-galera-node-1:172.18.0.2 \ --add-host irods-galera-node-3:172.18.0.4 \ mjstealey/irods-provider-galera:4.2.0 -vj setup_irods.py exec 3&amp;gt;&amp;amp;2 exec 2&amp;gt; /dev/null CL_SIZE=0 echo -n &amp;quot;Waiting for irods-galera-node-2 &amp;quot; while [ &amp;quot;${CL_SIZE}&amp;quot; != &#39;2&#39; ]; do sleep 2s LINE=$(docker exec irods-galera-node-2 mysql -uroot -ptemppassword -e &amp;quot;SHOW STATUS LIKE &#39;wsrep_cluster_size&#39;;&amp;quot; | grep wsrep_cluster_size) CL_SIZE=$(echo ${LINE} | cut -d &#39; &#39; -f 2) echo -n &amp;quot;.&amp;quot; done echo &amp;quot;&amp;quot; exec 2&amp;gt;&amp;amp;3 echo &amp;quot;[node-2 MySQL]&amp;gt; SHOW STATUS LIKE &#39;wsrep_cluster_size&#39;;&amp;quot; docker exec -ti irods-galera-node-2 mysql -uroot -ptemppassword -e &amp;quot;SHOW STATUS LIKE &#39;wsrep_cluster_size&#39;;&amp;quot; echo &amp;quot;[node-2 MySQL]&amp;gt; SHOW databases;&amp;quot; docker exec -ti irods-galera-node-2 mysql -uroot -ptemppassword -e &amp;quot;SHOW databases;&amp;quot; echo &amp;quot;[node-2 MySQL]&amp;gt; SHOW grants FOR &#39;irods&#39;@&#39;localhost&#39;;&amp;quot; docker exec -ti irods-galera-node-2 mysql -uroot -ptemppassword ICAT -e \ &amp;quot;SHOW grants FOR &#39;irods&#39;@&#39;localhost&#39;;&amp;quot; # init irods-galera-node-3 echo &amp;quot;### start irods-galera-node-3 and join cluster &#39;galera&#39; ###&amp;quot; docker run -d --name irods-galera-node-3 -h irods-galera-node-3 \ --env-file=env/irods-galera-node-3.env \ --net galeranet \ --ip 172.18.0.4 \ --add-host irods-galera-node-1:172.18.0.2 \ --add-host irods-galera-node-2:172.18.0.3 \ mjstealey/irods-provider-galera:4.2.0 -vj setup_irods.py exec 3&amp;gt;&amp;amp;2 exec 2&amp;gt; /dev/null CL_SIZE=0 echo -n &amp;quot;Waiting for irods-galera-node-3 &amp;quot; while [ &amp;quot;${CL_SIZE}&amp;quot; != &#39;3&#39; ]; do sleep 2s LINE=$(docker exec irods-galera-node-3 mysql -uroot -ptemppassword -e &amp;quot;SHOW STATUS LIKE &#39;wsrep_cluster_size&#39;;&amp;quot; | grep wsrep_cluster_size) CL_SIZE=$(echo ${LINE} | cut -d &#39; &#39; -f 2) echo -n &amp;quot;.&amp;quot; done echo &amp;quot;&amp;quot; exec 2&amp;gt;&amp;amp;3 echo &amp;quot;[node-3 MySQL]&amp;gt; SHOW STATUS LIKE &#39;wsrep_cluster_size&#39;;&amp;quot; docker exec -ti irods-galera-node-3 mysql -uroot -ptemppassword -e \ &amp;quot;SHOW STATUS LIKE &#39;wsrep_cluster_size&#39;;&amp;quot; echo &amp;quot;[node-3 MySQL]&amp;gt; SHOW databases;&amp;quot; docker exec -ti irods-galera-node-3 mysql -uroot -ptemppassword -e &amp;quot;SHOW databases;&amp;quot; echo &amp;quot;[node-3 MySQL]&amp;gt; SHOW STATUS LIKE &#39;wsrep_incoming_addresses&#39;;&amp;quot; docker exec -ti irods-galera-node-3 mysql -uroot -ptemppassword -e \ &amp;quot;SHOW STATUS LIKE &#39;wsrep_incoming_addresses&#39;;&amp;quot; echo &amp;quot;[node-3 MySQL]&amp;gt; SHOW grants FOR &#39;irods&#39;@&#39;localhost&#39;;&amp;quot; docker exec -ti irods-galera-node-3 mysql -uroot -ptemppassword ICAT -e \ &amp;quot;SHOW grants FOR &#39;irods&#39;@&#39;localhost&#39;;&amp;quot; echo &amp;quot;[node-3 MySQL]&amp;gt; SHOW FULL TABLES IN ICAT;&amp;quot; docker exec -ti irods-galera-node-3 mysql -uroot -ptemppassword -e &amp;quot;SHOW FULL TABLES IN ICAT;&amp;quot; exit 0; Expected output $ ./three-node-test.sh ### create docker network galeranet if it does not exist ### ### stop / remove existing containers ### irods-galera-node-1 irods-galera-node-2 irods-galera-node-3 irods-galera-node-1 irods-galera-node-2 irods-galera-node-3 ### show usage ### iRODS Provider - Galera Cluster docker-entrypoint.sh [-hijvd] [-f filename.sql] [arguments] options: -h show brief help -i initialize iRODS Galera cluster -j join existing iRODS Galera cluster -v verbose output -d dump database as db.sql to volume mounted as /LOCAL/PATH:/init -f filename.sql provide SQL script to initialize database from volume mounted as /LOCAL/PATH:/init Example: $ docker run --rm mjstealey/irods-provider-galera:4.2.0 -h # show help $ docker run -d mjstealey/irods-provider-galera:4.2.0 -iv setup_irods.py # init with default settings ### start irods-galera-node-1 and initialize cluster &#39;galera&#39; with initialize.sql file ### c88d3a730157ab47124844288a916a69b5cd172208bea8599b3c3324f289a278 Waiting for irods-galera-node-1 ........ [node-1 MySQL]&amp;gt; SHOW STATUS LIKE &#39;wsrep_cluster_size&#39;; +--------------------+-------+ | Variable_name | Value | +--------------------+-------+ | wsrep_cluster_size | 1 | +--------------------+-------+ [node-1 MySQL]&amp;gt; SHOW databases; +--------------------+ | Database | +--------------------+ | ICAT | | information_schema | | mysql | | performance_schema | +--------------------+ [node-1 MySQL]&amp;gt; SHOW grants FOR &#39;irods&#39;@&#39;localhost&#39;; +--------------------------------------------------------------------------------------------------------------+ | Grants for irods@localhost | +--------------------------------------------------------------------------------------------------------------+ | GRANT USAGE ON *.* TO &#39;irods&#39;@&#39;localhost&#39; IDENTIFIED BY PASSWORD &#39;*60E38376E2C974797971A03D9BEEF1F5EB169FEA&#39; | | GRANT ALL PRIVILEGES ON `ICAT`.* TO &#39;irods&#39;@&#39;localhost&#39; | +--------------------------------------------------------------------------------------------------------------+ ### start irods-galera-node-2 and join cluster &#39;irods-galera&#39; ### 6550de449e727405557f2042f43cd9947e8adac6954f3f6f5a40205aa8c06446 Waiting for irods-galera-node-2 .......... [node-2 MySQL]&amp;gt; SHOW STATUS LIKE &#39;wsrep_cluster_size&#39;; +--------------------+-------+ | Variable_name | Value | +--------------------+-------+ | wsrep_cluster_size | 2 | +--------------------+-------+ [node-2 MySQL]&amp;gt; SHOW databases; +--------------------+ | Database | +--------------------+ | ICAT | | information_schema | | mysql | | performance_schema | +--------------------+ [node-2 MySQL]&amp;gt; SHOW grants FOR &#39;irods&#39;@&#39;localhost&#39;; +--------------------------------------------------------------------------------------------------------------+ | Grants for irods@localhost | +--------------------------------------------------------------------------------------------------------------+ | GRANT USAGE ON *.* TO &#39;irods&#39;@&#39;localhost&#39; IDENTIFIED BY PASSWORD &#39;*60E38376E2C974797971A03D9BEEF1F5EB169FEA&#39; | | GRANT ALL PRIVILEGES ON `ICAT`.* TO &#39;irods&#39;@&#39;localhost&#39; | +--------------------------------------------------------------------------------------------------------------+ ### start irods-galera-node-3 and join cluster &#39;galera&#39; ### fe46da1faf9f9417243f989f2a17d939b45f2df1b88ea5077594af2c594d3521 Waiting for irods-galera-node-3 ........... [node-3 MySQL]&amp;gt; SHOW STATUS LIKE &#39;wsrep_cluster_size&#39;; +--------------------+-------+ | Variable_name | Value | +--------------------+-------+ | wsrep_cluster_size | 3 | +--------------------+-------+ [node-3 MySQL]&amp;gt; SHOW databases; +--------------------+ | Database | +--------------------+ | ICAT | | information_schema | | mysql | | performance_schema | +--------------------+ [node-3 MySQL]&amp;gt; SHOW STATUS LIKE &#39;wsrep_incoming_addresses&#39;; +--------------------------+-------------------------------------------------+ | Variable_name | Value | +--------------------------+-------------------------------------------------+ | wsrep_incoming_addresses | 172.18.0.4:3306,172.18.0.2:3306,172.18.0.3:3306 | +--------------------------+-------------------------------------------------+ [node-3 MySQL]&amp;gt; SHOW grants FOR &#39;irods&#39;@&#39;localhost&#39;; +--------------------------------------------------------------------------------------------------------------+ | Grants for irods@localhost | +--------------------------------------------------------------------------------------------------------------+ | GRANT USAGE ON *.* TO &#39;irods&#39;@&#39;localhost&#39; IDENTIFIED BY PASSWORD &#39;*60E38376E2C974797971A03D9BEEF1F5EB169FEA&#39; | | GRANT ALL PRIVILEGES ON `ICAT`.* TO &#39;irods&#39;@&#39;localhost&#39; | +--------------------------------------------------------------------------------------------------------------+ [node-3 MySQL]&amp;gt; SHOW FULL TABLES IN ICAT; +-------------------------+------------+ | Tables_in_ICAT | Table_type | +-------------------------+------------+ | R_COLL_MAIN | BASE TABLE | | R_DATA_MAIN | BASE TABLE | | R_GRID_CONFIGURATION | BASE TABLE | | R_META_MAIN | BASE TABLE | | R_MICROSRVC_MAIN | BASE TABLE | | R_MICROSRVC_VER | BASE TABLE | | R_OBJT_ACCESS | BASE TABLE | | R_OBJT_AUDIT | BASE TABLE | | R_OBJT_DENY_ACCESS | BASE TABLE | | R_OBJT_METAMAP | BASE TABLE | | R_ObjectId_seq_tbl | BASE TABLE | | R_QUOTA_MAIN | BASE TABLE | | R_QUOTA_USAGE | BASE TABLE | | R_RESC_GROUP | BASE TABLE | | R_RESC_MAIN | BASE TABLE | | R_RULE_BASE_MAP | BASE TABLE | | R_RULE_DVM | BASE TABLE | | R_RULE_DVM_MAP | BASE TABLE | | R_RULE_EXEC | BASE TABLE | | R_RULE_FNM | BASE TABLE | | R_RULE_FNM_MAP | BASE TABLE | | R_RULE_MAIN | BASE TABLE | | R_SERVER_LOAD | BASE TABLE | | R_SERVER_LOAD_DIGEST | BASE TABLE | | R_SPECIFIC_QUERY | BASE TABLE | | R_TICKET_ALLOWED_GROUPS | BASE TABLE | | R_TICKET_ALLOWED_HOSTS | BASE TABLE | | R_TICKET_ALLOWED_USERS | BASE TABLE | | R_TICKET_MAIN | BASE TABLE | | R_TOKN_MAIN | BASE TABLE | | R_USER_AUTH | BASE TABLE | | R_USER_GROUP | BASE TABLE | | R_USER_MAIN | BASE TABLE | | R_USER_PASSWORD | BASE TABLE | | R_USER_SESSION_KEY | BASE TABLE | | R_ZONE_MAIN | BASE TABLE | +-------------------------+------------+ "
},
{
	"uri": "https://mjstealey.github.io/irods-provider-galera/parallel-put-get/",
	"title": "Parallel put / get tests",
	"tags": [],
	"description": "parallel put get test script",
	"content": "Parallel iput / iget This script required the installation of the parallel package (parallel-20160222-1.el7.noarch) to be installed on the CentOS 7 test VMs being used. The configuration shown below would generate 256 40 MB files and transfer them using 30 parallel job threads at a time performing either iput or iget commands against the target iRODS provider. The only modification made to this script in the CentOS 7 test environment was to modify the TARGET_RESOURCE=&amp;quot;demoResc&amp;quot; to be either galera1Resc, galera2Resc, or galera3Resc depending on which node was being pointed at. parallel_put_get.sh #!/bin/bash -e ############################### # # This script will attempt parallel puts and gets # using the environment&#39;s iput/iget iCommands. # # This script will exit only when encountering an error. # # - JOBS is the number of parallel jobs # # - Creates FILES_TO_CREATE FILESIZE_IN_MB MiB files in FILES_FULLPATH # - Puts the files into BENCHMARKS_COLL # - Gets the files into BENCHMARKS_FULLPATH # ############################### SCRIPTPATH=$( cd $(dirname $0) ; pwd -P ) TIMESTAMPISH=$( date +%s )${RANDOM} RELATIVEPATH=&amp;quot;scratch_for_parallelputget/${TIMESTAMPISH}&amp;quot; FILESIZE_IN_MB=40 FILES_TO_CREATE=256 FILES_DIR=&amp;quot;${RELATIVEPATH}/files.dir&amp;quot; BENCHMARKS_COLL=&amp;quot;${RELATIVEPATH}/benchmarks.coll&amp;quot; TARGET_RESOURCE=&amp;quot;demoResc&amp;quot; JOBS=30 FILES_FULLPATH=${SCRIPTPATH}/${FILES_DIR} BENCHMARKS_FULLPATH=${SCRIPTPATH}/${BENCHMARKS_COLL} #################################### # generate files #################################### mkdir -p ${FILES_FULLPATH} for i in `seq -w ${FILES_TO_CREATE}` do truncate -s${FILESIZE_IN_MB}M ${FILES_FULLPATH}/bigfile.${i} echo ${i} &amp;gt;&amp;gt; ${FILES_FULLPATH}/bigfile.${i} done #################################### # generate scripts #################################### mkdir -p ${BENCHMARKS_FULLPATH} for i in `ls ${FILES_FULLPATH}` do echo iput -R ${TARGET_RESOURCE} -K -f ${FILES_FULLPATH}/${i} ${BENCHMARKS_COLL}/ done &amp;gt; ${BENCHMARKS_FULLPATH}/iput-all for i in `ls ${FILES_FULLPATH}` do echo iget -R ${TARGET_RESOURCE} -K -f ${BENCHMARKS_COLL}/${i} ${BENCHMARKS_FULLPATH}/ done &amp;gt; ${BENCHMARKS_FULLPATH}/iget-all #################################### # parallel put and get #################################### imkdir -p ${BENCHMARKS_COLL} irm -rf ${BENCHMARKS_COLL} imkdir -p ${BENCHMARKS_COLL} COUNT=0 time while [ &amp;quot;$?&amp;quot; == &amp;quot;0&amp;quot; ]; do COUNT=$((COUNT+1)) date echo &amp;quot;Starting loop ${COUNT}&amp;quot; echo &amp;quot; put&amp;quot; cat ${BENCHMARKS_FULLPATH}/iput-all | parallel -j ${JOBS} if [ &amp;quot;$?&amp;quot; != &amp;quot;0&amp;quot; ]; then date exit 1 fi echo &amp;quot; get&amp;quot; cat ${BENCHMARKS_FULLPATH}/iget-all | parallel -j ${JOBS} done "
},
{
	"uri": "https://mjstealey.github.io/irods-provider-galera/_header/",
	"title": "irods-provider-galera",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://mjstealey.github.io/irods-provider-galera/",
	"title": "Home",
	"tags": [],
	"description": "homepage",
	"content": "WORK IN PROGRESS iRODS Provider Galera The following pages describe the inspiration for, setup &amp;amp; configuration of, and testing methods used to deploy a proof of concept multi-node iRODS provider with ICAT catalog services via MariaDB Galera cluster implemented in Docker. Github repository: mjstealey/irods-provider-galera 1. Introduction 2. Setup 3. Testing "
},
{
	"uri": "https://mjstealey.github.io/irods-provider-galera/testing/",
	"title": "Testing",
	"tags": [],
	"description": "Testing irods-provider-galera",
	"content": "Methods of testing run_tests.py on a single node Every installation of iRODS includes a python script that will run various tests located at /var/lib/irods/scripts/run_tests.py $ python run_tests.py --help Usage: run_tests.py [options] Options: -h, --help show this help message and exit --run_specific_test=dotted name --run_python_suite --include_auth_tests --run_devtesty --topology_test=&amp;lt;icat|resource&amp;gt; --catch_keyboard_interrupt --use_ssl --no_buffer --xml_output --federation=&amp;lt;remote irods version, remote zone, remote host&amp;gt; run_tests.py on multiple nodes using netem parallel_put_get.sh on multiple nodes parallel_put_get.sh on multiple nodes using netem "
},
{
	"uri": "https://mjstealey.github.io/irods-provider-galera/introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "Introduction to irods-provider-galera",
	"content": "Why use MariaDB Galera cluster to service the iRODS catalog provider? An iRODS use case was presented where multiple geographically disparate participants all wanted to belong to the same iRODS Zone for ease of search and discovery. There was a desire to be able to decentralize the normally singular ICAT catalog database in a way that all participants could make use of whichever ICAT provider was closest to them without having to federate iRODS zones if new nodes came online. Initial requirements: Every iRODS provider node would contain the ICAT catalog and resource storage space that could be uniquely assigned to that node Large files would be transferred to the storage space of the iRODS provider node closest to the point of file origination All nodes must pass some sort of quality of service testing beyond the standard iRODS test suite The solution being presented here uses MariaDB configured as a Galera cluster to decentralize the ICAT catalog database across all participating iRODS provider nodes. A proof of concept testbed comprised of three iRODS provider nodes has been stood up to form a single zone named galeraZone. Each node within the testbed exists as it&amp;rsquo;s own VM, and can be configured to use various latency values via NetEm to simulate the kind of network traffic that would be experienced in a WAN configuration. References iRODS What is iRODS: The Integrated Rule-Oriented Data System (iRODS) is open source data management software used by research organizations and government agencies worldwide. iRODS is released as a production-level distribution aimed at deployment in mission critical environments. It virtualizes data storage resources, so users can take control of their data, regardless of where and on what device the data is stored. The development infrastructure supports exhaustive testing on supported platforms. The plugin architecture supports microservices, storage systems, authentication, networking, databases, rule engines, and an extensible API. Learn more at: irods.org MariaDB Why MariaDB: MariaDB is an open source leader, collaborating with innovators like Alibaba, Google and Facebook to develop and incorporate new features and improvements for the whole community, while at the same time helping customers like DBS Bank standardize on MariaDB solutions – ensuring enterprise and architecture requirements are met, now and in the future. Learn more at: mariadb.com Galera cluster What is MariaDB Galera cluster? About MariaDB Galera Cluster is a synchronous multi-master cluster for MariaDB. It is available on Linux only, and only supports the XtraDB/InnoDB storage engines (although there is experimental support for MyISAM - see the wsrep_replicate_myisam system variable). Starting with MariaDB 10.1, the wsrep API for Galera Cluster is included by default. This is available as a separate download for MariaDB 10.0 and MariaDB 5.5. Features Synchronous replication Active-active multi-master topology Read and write to any cluster node Automatic membership control, failed nodes drop from the cluster Automatic node joining True parallel replication, on row level Direct client connections, native MariaDB look &amp;amp; feel Benefits The above features yield several benefits for a DBMS clustering solution, including: No slave lag No lost transactions Both read and write scalability Smaller client latencies The Getting Started with MariaDB Galera Cluster page has instructions on how to get up and running with MariaDB Galera Cluster. Learn more at: what-is-mariadb-galera-cluster "
},
{
	"uri": "https://mjstealey.github.io/irods-provider-galera/setup/",
	"title": "Setup &amp; Configuration",
	"tags": [],
	"description": "Setup irods-provider-galera",
	"content": "Three node testbed Docker network configuration Galera VM configuration "
},
{
	"uri": "https://mjstealey.github.io/irods-provider-galera/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://mjstealey.github.io/irods-provider-galera/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]